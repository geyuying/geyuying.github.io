<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Yuying Ge, CS, HKU, The University of Hong Kong">
<meta name="description" content="Yuying Ge&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Yuying Ge&#39;s Homepage</title>
<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-159069803-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
-->
</head>
<body>
<div id="layout-content" style="margin-top:25px">
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Yuying Ge <font face="Arial">    葛玉莹 </font></h1></div>

				<h3>Ph.D. Candidate</h3>
				<p>
					Dept. of Computer Science <br>
					The University of Hong Kong <br>
					Pokfulam, Hong Kong<br>
					<br>
					Email: <a href="mailto:yyge13@gmail.com">yyge13 AT gmail</a><br>
				</p>
				<p>
					<a href="https://github.com/geyuying"><img src="./pic/others/github_logo.png" height="30px"></a>&nbsp;&nbsp;
					<a href="https://scholar.google.com/citations?user=hv1LiiEAAAAJ&hl=en"><img src="./pic/others/google_scholar_logo.png" height="30px"></a>&nbsp;&nbsp;
				</p>
				</p>
			</td>
			<td>
    <img src="./pic/yuyingge.jpg" border="0" width="180"><br>
   </td>
		</tr><tr>
	</tr></tbody>
</table>

<!--<h2>Biography [<a href="./CV-JinYueming.pdf">CV</a>]</h2>-->
<h2>Biography </h2>
<p>
	I am currently a fourth-year (2019-now) Ph.D. student in the Department of Computer Science, the University of Hong Kong,
	under the supervision of <a href="http://luoping.me/">Prof. Ping Luo</a>. I am also a visiting student at UCSD,
	working with <a href="https://xiaolonw.github.io/">Prof. Xiaolong Wang</a>. Before that, I received bachelor's degree in Communication Engineering
	at University of Electronic Science and Technology of China (UESTC) in 2018, ranking 1/525. My research interests include computer vision, deep learning,
	with recent focus on large-scale multi-modality pre-training and its applications.
	<br>
</p>



<h2>News</h2>
<ul>
	<li>
		[07/2022] One paper was accepted by ECCV 2022.
	</li>	
	<li>
		[03/2022] One paper was accepted by CVPR 2022 as oral.
	</li>
	<li>
		[11/2021] One paper was accepted by IEEE TIP.
	</li>
	<li>
		[03/2021] Two papers were accepted by CVPR 2021.
	</li>
	<li>
		[03/2019] One paper was accepted by CVPR 2019.
	</li>
</ul>




<h2> Publications</h2>
<table id="tbPublications" width="100%">
	<tbody>

			<tr>
	<td><center><img width="200" src="./pic/paper/TVTS.jpeg"></center></td>
	<td>
		<font size="2">Learning Transferable Spatiotemporal Representations from Natural Script Knowledge,
		<br>
		<i>Ziyun Zeng*, <b>Yuying Ge*</b>, Xihui Liu, Bin Chen, Ping Luo, Shu-Tao Xia, Yixiao Ge</i>
		<br>
		arXiv preprint, 2022
		<br>
			[<a href='https://arxiv.org/abs/2209.15280' target="_blank"><b>paper</b></a>|<a href='https://github.com/TencentARC/TVTS' target="_blank"><b>code</b></a>]
		</td>

		<tr>
	<td><center><img width="250" src="./pic/paper/MILES.jpg"></center></td>
	<td>
		<font size="2">MILES: Visual BERT Pre-training with Injected Language Semantics for Video-text Retrieval,
		<br>
		<i><b>Yuying Ge</b>, Yixiao Ge, Xihui Liu, Alex Jinpeng Wang, Jianping Wu, Ying Shan, Xiaohu Qie and Ping Luo</i>
		<br>
		European Conference on Computer Vision (<b>ECCV</b>) 2022
		<br>
			[<a href='https://arxiv.org/abs/2204.12408' target="_blank"><b>paper</b></a>|<a href='https://github.com/TencentARC/MCQ/blob/main/MILES.md' target="_blank"><b>code</b></a>]
		</td>

	</tr>

	<tr>
	<td><center><img width="250" src="./pic/paper/MCQ.jpg"></center></td>
	<td>
		<font size="2">Bridging Video-text Retrieval with Multiple Choice Questions,
		<br>
		<i><b>Yuying Ge</b>, Yixiao Ge, Xihui Liu, Dian Li, Ying Shan, Xiaohu Qie and Ping Luo</i>
		<br>
		IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2022 (<b>oral</b>)
		<br>
		[<a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Ge_Bridging_Video-Text_Retrieval_With_Multiple_Choice_Questions_CVPR_2022_paper.pdf' target="_blank"><b>paper</b></a>|<a href='https://github.com/TencentARC/MCQ' target="_blank"><b>code</b></a>|<a href='MCQ.html' target="_blank"><b>project</b></a>]
		</td>

	</tr>

		<tr>
	<td><center><img width="250" src="./pic/paper/metadance.jpg"></center></td>
	<td>
		<font size="2">MetaDance: Few-shot Dancing Video Retargeting via Temporal-aware Meta-learning,
		<br>
		<i><b>Yuying Ge</b>, Yibing Song, Ruimao Zhang and Ping Luo</i>
		<br>
		arXiv preprint, 2022
		<br>
		[<a href='https://arxiv.org/abs/2201.04851' target="_blank"><b>paper</b></a>|<a href='https://github.com/geyuying/MetaDance' target="_blank"><b>demo</b></a>]
		</td>

	</tr>
	<tr>
	<td><center><img width="250" src="./pic/paper/metacloth.jpg"></center></td>
	<td>
		<font size="2">MetaCloth: Learning Unseen Tasks of Dense Fashion Landmark Detection from a Few Samples,
		<br>
		<i><b>Yuying Ge</b>, Ruimao Zhang, and Ping Luo</i>
		<br>
		IEEE Transactions on Image Processing (<b>TIP</b>) 2021
		<br>
		[<a href='https://arxiv.org/abs/2112.02763' target="_blank"><b>paper</b></a>]
		</td>

	</tr>

	<tr>
	<td><center><img width="250" src="./pic/paper/cvpr2021_pfafn.png"></center></td>
	<td>
		<font size="2">Parser-Free Virtual Try-on via Distilling Appearance Flows,
		<br>
		<i><b>Yuying Ge</b>, Yibing Song, Ruimao Zhang, Chongjian Ge, Wei Liu, and Ping Luo</i>
		<br>
		IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2021
		<br>
		[<a href='https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_Parser-Free_Virtual_Try-On_via_Distilling_Appearance_Flows_CVPR_2021_paper.pdf' target="_blank"><b>paper</b></a>|<a href='https://github.com/geyuying/PF-AFN' target="_blank"><b>code</b></a>]
		</td>

	</tr>

	<!--<tr>
		<td><center><img width="250" src="./pic/paper/cvpr2021_dcton.png"></center></td>
		<td>
			<font size="2">Disentangled Cycle Consistency for Highly-realistic Virtual Try-On,
			<br>
			<i>Chongjian Ge, Yibing Song, <b>Yuying Ge</b>, Han Yang, Wei Liu, and Ping Luo</i>
			<br>
			IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2021
			<br>
			[<a href='https://arxiv.org/abs/2103.09479' target="_blank"><b>paper</b></a>|<a href='https://github.com/ChongjianGE/DCTON' target="_blank"><b>code</b></a>]
		</td>
	</tr>-->

	<tr>
	<td><center><img width="250" src="./pic/paper/deepfashion2.jpg"></center></td>
	<td>
		<font size="2">DeepFashion2: A Versatile Benchmark for Detection, Pose Estimation, Segmentation and Re-Identification of Clothing Images,
		<br>
		<i><b>Yuying Ge</b>, Ruimao Zhang, Xiaogang Wang, Xiaoou Tang, and Ping Luo</i>
		<br>
		IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2019
		<br>
		[<a href='https://openaccess.thecvf.com/content_CVPR_2019/papers/Ge_DeepFashion2_A_Versatile_Benchmark_for_Detection_Pose_Estimation_Segmentation_and_CVPR_2019_paper.pdf'  target="_blank"><b>paper</b></a>|<a href='https://github.com/switchablenorms/DeepFashion2' target="_blank"><b>dataset</b></a>]
		</td>




</tbody></table>


<h2><font> Teaching </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  HKU COMP3340 Applied Deep Learning <br>
		  HKU COMP3250 Design and Analysis of Algorithms <br>
	  </font> </p>
</ul>

	<h2><font> Experiences </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Research Assistant in Multimedia Lab (MMLab), The Chinese University of Hong Kong, 2018-2019 <br>
		  Intern in SenseTime, 2017-2018 <br>
	  </font> </p>
</ul>

<h2><font> Academic Activities </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Organizer of DeepFashion2 Challenge <a href='https://competitions.codalab.org/competitions/22966'>Clothes Landmark Detection</a>
			  and <a href='https://competitions.codalab.org/competitions/22967'>Clothes Retrieval</a> in 2019, 2020<br>
		  Organizer of <a href='https://sites.google.com/view/cvcreative2020'>Third Workshop on Computer Vision for Fashion, Art and Design</a> in CVPR, 2020 <br>
		  Organizer of <a href='https://sites.google.com/view/cvcreative/home?authuser=0'>Sencond Workshop on Computer Vision for Fashion, Art and Design</a> in ICCV, 2019 <br>
	  </font> </p>
</ul>

<h2><font> Honors and Awards </font></h2>
<ul style="list-style-type:none">
	  <p style="margin-left: 0px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><font size="3"><meta charset="utf-8">
		  Outstanding Graduates of Sichuan Province,  2018 <br>
		  National Scholarship, 2015-2016 <br>
          National Scholarship, 2014-2015 <br>
	  </font> </p>
</ul>

<p align=right>
	<a class="pull-right" href="#">
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=zPFGAwps3dHeHg_L_f7k-PGV37THUtOVbgXT6ZedWOs&cl=ffffff&w=a"></script></center>
	</a>
</p>

<p><center><font>
        <br>&copy; Yuying Ge | Last updated: Dec. 2021</font></center>
</p>

</div>
</body></html>
